{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fraud Detection\n",
    "## Ubisoft home assignment\n",
    "Arnaud Baumann"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Some statistics about the dataset\n",
    "\n",
    "We will first show some statistics about the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "from assembleAdaboost import AssembleAdaBoost\n",
    "import pickle\n",
    "from utils import *\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First read the csv with pandas and transform it to a dataframe\n",
    "df = pd.read_csv(\"mle_fraud_test.csv\", sep=\";\")\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I kept most of the features unchanged. I dropped the `order_id` column as each order has a unique ID.\n",
    "For the rest of the features, I only transformed `user_id` and `order_created_datetime` features because\n",
    "they had too high cardinality:\n",
    "* Each `user_id` has been replaced by the number of times it appears in the train set (`user_id_count`).\n",
    "* The range of `order_created_datetime` has been reduced by keeping only the day number of the month (`day_number`)\n",
    "\n",
    "Let's try to visualize the data distributions with a pairplot. We sample `n_samples = 300` from each class and\n",
    "then plot some of the features for each class by using seaborn's pairplot\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sample for each class 300 points\n",
    "n_samples = 300\n",
    "legit_df = df[df[\"transaction_status\"]==\"LEGIT\"].sample(n=n_samples)\n",
    "fraud_df = df[df[\"transaction_status\"]==\"FRAUD\"].sample(n=n_samples)\n",
    "blocked_df = df[df[\"transaction_status\"]==\"BLOCKED\"].sample(n=n_samples)\n",
    "X_legit = get_df_features(legit_df)\n",
    "X_fraud= get_df_features(fraud_df)\n",
    "X_blocked = get_df_features(blocked_df)\n",
    "\n",
    "data = np.concatenate([X_legit, X_fraud,X_blocked])\n",
    "# Create user_id_counter\n",
    "user_id_counter = dict(Counter( data[:,0]))\n",
    "\n",
    "# Preprocess the data\n",
    "preprocess(data, user_id_counter)\n",
    "labs = np.array([['LEGIT'] for i in range(n_samples)]+\n",
    "                [['FRAUD'] for i in range(n_samples)]+\n",
    "                [['BLOCKED'] for i in range(n_samples)])\n",
    "\n",
    "data = np.append(data, labs, axis=1)\n",
    "\n",
    "data_df = pd.DataFrame(data=data)\n",
    "data_df.columns = [\"user_id_count\", \"day_number\", \"amount\", \"total_amount_14days\", \"email_handle_length\", \\\n",
    "         \"email_handle_dst_char\", \"total_nb_orders_player\", \"player_seniority\", \\\n",
    "         \"total_nb_play_sessions\", \"geographic_distance_risk\", \"label\"]\n",
    "g = sns.pairplot(data_df[['amount','day_number', 'total_amount_14days', 'email_handle_dst_char', 'geographic_distance_risk','label']], hue='label')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset imbalance\n",
    "\n",
    "Datasets for fraud detection are usually very unbalanced, as the majority of samples are valid\n",
    "(LEGIT in our case). Here we have an additionnal third class named 'BLOCKED' meaning that the existing fraud\n",
    "management tool has stopped the transaction and we do not have a final label for it. We refer in this notebook\n",
    "to data with 'BLOCKED' label with variables containing 'blocked'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_legits = len(df[df[\"transaction_status\"]==\"LEGIT\"])\n",
    "num_blocked = len(df[df[\"transaction_status\"]==\"BLOCKED\"])\n",
    "num_frauds = len(df[df[\"transaction_status\"]==\"FRAUD\"])\n",
    "num_payments = len(df[\"transaction_status\"])\n",
    "print(\"Number of legit payments: {} ouf of {} ({:.4f}%)\".format( num_legits, num_payments, num_legits/num_payments))\n",
    "print(\"Number of blocked payments: {} ouf of {} ({:.4f}%)\".format( num_blocked, num_payments, num_blocked/num_payments))\n",
    "print(\"Number of fraud payments: {} ouf of {} ({:.4f}%)\".format( num_frauds, num_payments, num_frauds/num_payments))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ASSEMBLE.Adaboost algorithm\n",
    "\n",
    "\n",
    "The ASSEMBLE.Adaboost is implemented in the file `assembleAdaBoost.py` as a class named AssembleAdaBoost.\n",
    "<b>(Question 1) </b>.\n",
    "\n",
    "### Answer to question 2:\n",
    "\n",
    "You can find below a code cell that trains the assembleAdaBoost algorithm and\n",
    "outputs the resulting confusion matrix on the test set. I chose a split ratio between train and test of 75%\n",
    "for train and 25% for test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "from time import time, strftime\n",
    "\n",
    "# Read the dataframe and get labeled and unlabeled data\n",
    "df = pd.read_csv(\"mle_fraud_test.csv\", sep=\";\")\n",
    "not_blocked_df = df[df[\"transaction_status\"]!=\"BLOCKED\"]\n",
    "blocked_df = df[df[\"transaction_status\"]==\"BLOCKED\"]\n",
    "\n",
    "\n",
    "y_labeled = get_df_labels(not_blocked_df)\n",
    "X_train_blocked = get_df_features(blocked_df)\n",
    "X_labeled = get_df_features(not_blocked_df)\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled, \\\n",
    "                                                    stratify=y_labeled, \\\n",
    "                                                    test_size=0.25, \\\n",
    "                                                    shuffle=True)\n",
    "\n",
    "# Create user_id_dictionary based on the train dataset\n",
    "user_id_counter = dict(Counter( np.concatenate([X_train[:,0], X_train_blocked[:,0]]) ))\n",
    "# Save the dictionnary as we are going to reuse it in the app\n",
    "file = open('user_id_counter.pkl', 'wb')\n",
    "pickle.dump(user_id_counter, file)\n",
    "file.close()\n",
    "\n",
    "# Transform user_id and order_created_datetime features\n",
    "print('Preprocessing data...')\n",
    "preprocess(X_train, user_id_counter)\n",
    "preprocess(X_test, user_id_counter)\n",
    "preprocess(X_train_blocked, user_id_counter)\n",
    "# Initialize pseudo-labels for blocked data\n",
    "y_train_blocked = get_initial_blocked_labels(X_train, y_train, X_train_blocked)\n",
    "\n",
    "print(\"Starting model fitting...\")\n",
    "start = time()\n",
    "clf = AssembleAdaBoost(n_estimators=50, sample=False)\n",
    "clf.fit(X_train.astype(float), X_train_blocked.astype(float),y_train, y_train_blocked)\n",
    "elapsed = time()-start\n",
    "print(\"Done training, took {:.2f}s. doing prediction...\\n\".format(elapsed))\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Save the fitted model with pickle\n",
    "file = open('assemble_adaboost_model.pkl', 'wb')\n",
    "pickle.dump(clf, file)\n",
    "file.close()\n",
    "\n",
    "# Print metrcis and the confusion matrix\n",
    "print_metrics(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(cm, [\"FRAUD\", \"LEGIT\"], normalize=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assemble Adaboost benchmark\n",
    "\n",
    "To see if the algorithm performs well, we can compare it to a similar model, Adaboost. To do so, we use sklearn's\n",
    "AdaBoostClassifier class and perform 4-fold classification on the dataset for both classifiers."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "df = pd.read_csv(\"mle_fraud_test.csv\", sep=\";\")\n",
    "\n",
    "not_blocked_df = df[df[\"transaction_status\"]!=\"BLOCKED\"]\n",
    "blocked_df = df[df[\"transaction_status\"]==\"BLOCKED\"]\n",
    "\n",
    "y_labeled = get_df_labels(not_blocked_df)\n",
    "X_labeled = get_df_features(not_blocked_df)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "skf.get_n_splits(X_labeled, y_labeled)\n",
    "print(skf)\n",
    "\n",
    "for idx, (train_index, test_index) in enumerate(skf.split(X_labeled, y_labeled)):\n",
    "    print(\"\\ncurrent k-fold:\", idx+1)\n",
    "\n",
    "    X_train_labeled, X_test = X_labeled[train_index], X_labeled[test_index]\n",
    "    y_train_labeled, y_test= y_labeled[train_index], y_labeled[test_index]\n",
    "\n",
    "\n",
    "    user_id_counter = dict(Counter(X_train_labeled[:,0]))\n",
    "\n",
    "    preprocess(X_train_labeled, user_id_counter)\n",
    "    preprocess(X_test, user_id_counter)\n",
    "    X_train_blocked = get_df_features(blocked_df)\n",
    "    preprocess(X_train_blocked, user_id_counter)\n",
    "\n",
    "    y_train_blocked= get_initial_blocked_labels(X_train_labeled, y_train_labeled, X_train_blocked)\n",
    "\n",
    "    clf = AssembleAdaBoost(n_estimators=50, sample=False)\n",
    "\n",
    "    clf.fit(X_train_labeled.astype(float), X_train_blocked.astype(float),y_train_labeled, y_train_blocked)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"\\nASSEMBLE Adaboost classification metrics:\")\n",
    "    print_metrics(y_test, y_pred)\n",
    "\n",
    "    clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1, max_leaf_nodes=2),algorithm='SAMME')\n",
    "    clf.fit(X_train_labeled, y_train_labeled)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"\\nAdaboost classification metrics:\")\n",
    "    print_metrics(y_test, y_pred)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that Assemble.Adaboost classifier has similar performance or sometimes slightly below\n",
    "performances compared to Adaboost. The reason could be that blocked samples have very similar distribution\n",
    "to legit samples (see pairplot) and thus poorly contributing to the increase of performances of fraud classification."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer to question 3\n",
    "\n",
    "Taking the optimal decision here means to maximize the profit of the transaction given the transaction amount, the fraud\n",
    "fee and the probability that the transaction is a fraud. We can calculate the potential profit with\n",
    "the formula:\n",
    "\n",
    " `potential_profit = amount*(1-p) - p*fraud_fee`\n",
    "\n",
    "If this potential profit is above 0, we should allow the transaction. Otherwise, we blocked it as we\n",
    "potentially lose money.\n",
    "\n",
    "Below is a plot describing how this function behaves given different amount, a fixed fraud fee of 15€ and a variable\n",
    "probability of fraud.\n",
    "* When the amount increase, we can allow a higher probability of fraud.\n",
    "* At an amount of 15€ and p=0.5 the potential profit is 0, which makes sense.\n",
    "\n",
    "You'll also find a code cell with the associated method implemented."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "fraud_fee = 15.0\n",
    "amounts = [5, 10, 15, 25, 50]\n",
    "for amount in amounts:\n",
    "    p = np.arange(0.0, 1.0, 0.01)\n",
    "    potential_profit = amount*(1-p) - p*fraud_fee\n",
    "    line, = plt.plot(p, potential_profit, lw=2,label=\"amount: {}\".format(amount))\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "ax.set_ylabel(\"Decision score\")\n",
    "ax.set_xlabel(\"Probability of being fraud\")\n",
    "plt.ylim(-20, 20)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# optimal decision method\n",
    "def optimal_decision(amount, fraud_fee, p):\n",
    "    \"\"\"Computes the optimal decision between blocking or not blocking of the transaction\n",
    "        Parameters\n",
    "        ----------\n",
    "        amount : amount of the transaction\n",
    "        fraud_fee : fraud fee\n",
    "        p : probability of the transaction to be a fraud\n",
    "        Returns\n",
    "        -------\n",
    "        decision : boolean :\n",
    "                    True if the transaction must be blocked\n",
    "                    False if the transaction must not be blocked\n",
    "        \"\"\"\n",
    "    potential_profit  = amount*(1-p) - p*fraud_fee\n",
    "    if potential_profit < 0:\n",
    "        return 'BLOCK'\n",
    "    else:\n",
    "        return 'ACCEPT'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}